#cloud-config

# Complete VM setup for k3a cluster nodes
# Includes all packages needed for Kubernetes/kubeadm installation

package_update: true

packages:
  - curl
  - wget
  - git
  - unzip
  - ca-certificates
  - moby-runc
  - moby-containerd

# Complete system setup for Kubernetes
runcmd:
  # Install Azure CLI for CBL-Mariner (RPM-based)
  - sudo rpm --import https://packages.microsoft.com/keys/microsoft.asc
  - |
    cat <<EOF | sudo tee /etc/yum.repos.d/azure-cli.repo
    [azure-cli]
    name=Azure CLI
    baseurl=https://packages.microsoft.com/yumrepos/azure-cli
    enabled=1
    gpgcheck=1
    gpgkey=https://packages.microsoft.com/keys/microsoft.asc
    EOF
  - sudo tdnf install -y azure-cli
  
  # Setup container runtime
  - sudo systemctl enable --now containerd
  - sudo mkdir -p /etc/containerd
  - sudo containerd config default | sudo tee /etc/containerd/config.toml
  - sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
  - sudo systemctl restart containerd
  
  # Setup Kubernetes kernel modules and networking
  - |
    sudo tee /etc/modules-load.d/k8s.conf <<EOF
    overlay
    br_netfilter
    EOF
  - sudo modprobe overlay
  - sudo modprobe br_netfilter
  - |
    sudo tee /etc/sysctl.d/k8s.conf <<EOF
    net.bridge.bridge-nf-call-iptables  = 1
    net.bridge.bridge-nf-call-ip6tables = 1
    net.ipv4.ip_forward                 = 1
    EOF
  - sudo sysctl --system
  
  # Disable swap
  - sudo swapoff -a
  - sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
  
  # Setup Kubernetes repository and install packages
  - |
    sudo tee /etc/yum.repos.d/kubernetes.repo <<EOF
    [kubernetes]
    name=Kubernetes
    baseurl=https://pkgs.k8s.io/core:/stable:/v1.33/rpm/
    enabled=1
    gpgcheck=1
    gpgkey=https://pkgs.k8s.io/core:/stable:/v1.33/rpm/repodata/repomd.xml.key
    EOF
  - sudo tdnf install -y kubelet kubeadm kubectl
  - sudo systemctl enable kubelet
  
  # Ensure azureuser has proper SSH directory
  - sudo -u azureuser mkdir -p /home/azureuser/.ssh
  - sudo -u azureuser chmod 700 /home/azureuser/.ssh
  
  # Set hostname based on instance metadata (normalize Azure VMSS naming)
  - |
    INSTANCE_NAME=$(curl -s -H Metadata:true "http://169.254.169.254/metadata/instance/compute/name?api-version=2021-02-01&format=text" 2>/dev/null || echo "k3a-node")
    # Convert Azure VMSS naming (control-plane-vmss_1) to consistent format (control-plane-000001) 
    if [[ "$INSTANCE_NAME" =~ control-plane-vmss_([0-9]+) ]]; then
      INSTANCE_ID="${BASH_REMATCH[1]}"
      NORMALIZED_NAME=$(printf "control-plane-%06d" "$INSTANCE_ID")
      hostnamectl set-hostname "$NORMALIZED_NAME"
    else
      hostnamectl set-hostname "$INSTANCE_NAME"
    fi
  
  # Basic system optimization
  - echo 'vm.swappiness=10' >> /etc/sysctl.conf
  - sysctl -p

  # Auto-join worker nodes to cluster
  - |
    if [ "{{.Role}}" = "worker" ]; then
      echo "Starting worker node auto-join process..." >> /var/log/k3a-worker-join.log
      
      # Wait for Azure CLI to be available
      timeout 300 bash -c 'until az --version >/dev/null 2>&1; do sleep 5; done' || {
        echo "Azure CLI not available after timeout" >> /var/log/k3a-worker-join.log
        exit 1
      }
      
      # Login using managed identity
      az login --identity >> /var/log/k3a-worker-join.log 2>&1
      
      # Wait for worker join token to be available in Key Vault
      KEYVAULT_NAME="{{.KeyVaultName}}"
      SECRET_NAME="{{.ResourceGroup}}-worker-join"
      
      echo "Waiting for worker join token from Key Vault: $KEYVAULT_NAME" >> /var/log/k3a-worker-join.log
      for i in {1..60}; do
        if JOIN_COMMAND=$(az keyvault secret show --vault-name "$KEYVAULT_NAME" --name "$SECRET_NAME" --query "value" --output tsv 2>/dev/null); then
          echo "Retrieved worker join command" >> /var/log/k3a-worker-join.log
          break
        fi
        echo "Attempt $i: Worker join token not yet available, waiting..." >> /var/log/k3a-worker-join.log
        sleep 10
      done
      
      if [ -z "$JOIN_COMMAND" ]; then
        echo "Failed to retrieve worker join command after 10 minutes" >> /var/log/k3a-worker-join.log
        exit 1
      fi
      
      # Execute the join command
      echo "Executing kubeadm join..." >> /var/log/k3a-worker-join.log
      eval "sudo $JOIN_COMMAND" >> /var/log/k3a-worker-join.log 2>&1
      
      if [ $? -eq 0 ]; then
        echo "Worker node successfully joined the cluster!" >> /var/log/k3a-worker-join.log
        echo "worker-joined" > /var/lib/cloud/k3a-worker-status
      else
        echo "Failed to join worker node to cluster" >> /var/log/k3a-worker-join.log
        echo "worker-join-failed" > /var/lib/cloud/k3a-worker-status
        exit 1
      fi
    fi

write_files:
  # Create a marker file to indicate cloud-init completion
  - path: /var/lib/cloud/k3a-ready
    content: |
      Cloud-init setup completed for k3a cluster node
      All Kubernetes prerequisites installed
      Timestamp: $(date)
    permissions: '0644'

# Ensure services are enabled
bootcmd:
  - systemctl enable ssh

# Final message
final_message: "k3a node cloud-init setup completed. All prerequisites installed. Ready for kubeadm cluster initialization via SSH."
